{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstrating Gradient descent on a non-linear surface and compare its performance with coordinate descant\n",
    " $$E(u,v) = (ue^v - 2ve^{-u})^2$$\n",
    "Starting at $$(u,v) = (1,1) $$\n",
    "Make the learning rate $$\\eta = 0.1 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterate 10 times to get E = 1.2086833944220747e-15 at (u,v) = (0.04473629039778207,0.023958714099141746)\n",
      "After 15 iterations, E = 0.13981379199615315\n"
     ]
    }
   ],
   "source": [
    "## Calculate how many iterations does it take for the error to fall below 10^-14\n",
    "\n",
    "## Error function\n",
    "E = lambda u, v : ( u * np.exp(v) - 2 * v * np.exp(-u) ) ** 2 ## E\n",
    "\n",
    "## partial derivative of E with respect to u\n",
    "dEdu = lambda u, v: 2 * ( np.exp(v) + 2 * v * np.exp(-u)) * ( u * np.exp(v) - 2 * v * np.exp(-u) ) \n",
    "\n",
    "## partial derivative of E with respect to v\n",
    "dEdv = lambda u, v: 2 * ( u * np.exp(v) - 2 * np.exp(-u)) * ( u * np.exp(v) - 2 * v * np.exp(-u) )\n",
    "\n",
    "## Gradient of E\n",
    "delta_E = lambda u, v : (dEdu(u,v ) , dEdv(u,v))\n",
    "\n",
    "## Threshold\n",
    "threshold = 10e-14\n",
    "\n",
    "def gradient_descent():\n",
    "    \n",
    "    result = E(1,1) ## starting point\n",
    "    counts = 0 ## iterations\n",
    "    eta = 0.1 ## learning rate\n",
    "    u,v = 1,1 ## initial coords\n",
    "    \n",
    "    \n",
    "    while ( E(u,v) > threshold ) :\n",
    "    \n",
    "        gradient = delta_E(u,v)\n",
    "        u = u - eta * gradient[0] \n",
    "        v = v - eta * gradient[1]\n",
    "        counts += 1\n",
    "    \n",
    "    print(\"Iterate {} times to get E = {} at (u,v) = ({},{})\".format(counts, E(u,v), u, v))\n",
    "gradient_descent()\n",
    "\n",
    "\n",
    "'''\n",
    "    To compare the performance of coordinate descent, \n",
    "    I will compare the Error value after 15 full iterations\n",
    "    \n",
    "    Coordinate descent first adjust the u, reevaluate the gradient then adjust in v direction\n",
    "'''\n",
    "def coordinate_descent():\n",
    "    \n",
    "    eta = 0.1 ## learning rate\n",
    "    u,v = 1,1 ## initial coords\n",
    "    for i in range(15):\n",
    "\n",
    "        dedu = dEdu(u,v)\n",
    "        u = u - eta * dedu\n",
    "        dedv = dEdv(u,v)\n",
    "        v = v - eta * dedv\n",
    "\n",
    "    print(\"After 15 iterations, E = {}\".format(E(u,v)))\n",
    "    \n",
    "    \n",
    "coordinate_descent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "### Logistic Regression and Cross Entropy Error\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
